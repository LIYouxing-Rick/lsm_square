{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fed5a760-64f2-4e1a-a255-c9928191fbd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 测试 1: 验证归一化逻辑 ===\n",
      "原始 weight_v 形状: torch.Size([5])\n",
      "1D向量下: dim=0=2.8411, dim=-1=2.8411 (应该相等)\n",
      "修正后单位向量模长: 1.0000 (应为 1.0)\n",
      "修正后形状: torch.Size([5])\n",
      "\n",
      "=== 测试 2: 完整的前向和反向传播 ===\n",
      "输入 C 形状: torch.Size([2, 4, 4])\n",
      "参数 weight_v 形状: torch.Size([6])\n",
      "前向传播成功。输出形状: torch.Size([2, 1])\n",
      "反向传播成功。\n",
      "输入 C 的梯度范数: 27.0566\n",
      "参数 weight_v 的梯度范数: 2.6430\n"
     ]
    }
   ],
   "source": [
    "import torch as th\n",
    "import torch.nn as nn\n",
    "from scipy.special import beta\n",
    "from geoopt.manifolds import PoincareBall\n",
    "\n",
    "# --- 1. 粘贴您提供的基础工具函数 (保持不变) ---\n",
    "\n",
    "arsinh = th.asinh\n",
    "\n",
    "@th.jit.script\n",
    "def hemisphere_to_poincare(x):\n",
    "    x_T, x_n1 = x[..., :-1], x[..., -1]\n",
    "    y = x_T / (1 + x_n1.unsqueeze(-1))\n",
    "    return y\n",
    "\n",
    "@th.jit.script\n",
    "def unidirectional_poincare_mlr(x, z_norm, z_unit, r, c):\n",
    "    dtype = x.dtype\n",
    "    device = x.device\n",
    "    rc = th.sqrt(th.as_tensor(c, dtype=dtype, device=device))\n",
    "    z_unit = z_unit.to(dtype)\n",
    "    z_norm = z_norm.to(dtype)\n",
    "    r = r.to(dtype)\n",
    "    drcr = 2. * rc * r\n",
    "\n",
    "    rcx = rc * x\n",
    "    # 注意：这里假设 x 是 [Batch, Dim], 那么 cx2 应该是 [Batch, 1]\n",
    "    cx2 = rcx.pow(2).sum(dim=-1, keepdim=True)\n",
    "\n",
    "    # 关键点：matmul(rcx, z_unit)\n",
    "    # 如果 x 是 [Batch, Dim], z_unit 是 [Dim] (或者 [1, Dim])\n",
    "    # 结果应该是 [Batch, 1]\n",
    "    # 这里需要确保 z_unit 的形状能被广播或正确矩阵乘法\n",
    "    if z_unit.dim() == 1:\n",
    "        inner_prod = th.matmul(rcx, z_unit).unsqueeze(-1)\n",
    "    else:\n",
    "        # 假设 z_unit 是 [Dim, 1] 或者与 x 对齐\n",
    "        inner_prod = th.matmul(rcx, z_unit.t()) # 这里的具体实现取决于 z_unit 的定义形状，下面测试会调整\n",
    "\n",
    "    return 2 * z_norm / rc * arsinh(\n",
    "        (2. * inner_prod * th.cosh(drcr) - (1. + cx2) * th.sinh(drcr)) / th.clamp_min(1. - cx2, 1e-15))\n",
    "\n",
    "# --- 2. 定义修正后的类 ---\n",
    "\n",
    "class CorPolyHyperbolicCholeskyMetric(nn.Module):\n",
    "    def __init__(self, n, jitter: float = 1e-5):\n",
    "        super().__init__()\n",
    "        self.n = n\n",
    "        self.pball = PoincareBall(c=1.0, learnable=False)\n",
    "        self.register_buffer('c', th.tensor(1.0))\n",
    "        self.jitter = jitter\n",
    "\n",
    "    def correlation_to_poincare_concate(self, C):\n",
    "        # Step 1: Cholesky\n",
    "        I = th.eye(C.shape[-1], device=C.device, dtype=C.dtype)\n",
    "        L = th.linalg.cholesky(C + self.jitter * I)\n",
    "\n",
    "        # Step 2: Map\n",
    "        size = L.size()\n",
    "        # 注意：这里原始代码逻辑可能有点特定于输入维度，为测试简单化，假设输入 [Batch, n, n]\n",
    "        # product_dims 对于 [Batch, n, n] 应该是 1 (因为 size[1:-2] 是空的)\n",
    "        if len(size) > 3:\n",
    "            product_dims = th.prod(th.tensor(size[1:-2])).item()\n",
    "        else:\n",
    "            product_dims = 1.0\n",
    "            \n",
    "        dim_in = int(product_dims * size[-1] * (size[-1] - 1) / 2)\n",
    "        beta_n = beta(dim_in / 2, 1 / 2)\n",
    "        mapped_rows = []\n",
    "        \n",
    "        for i in range(1, L.shape[-2]):\n",
    "            hs_r = L[..., i, :i+1]\n",
    "            pball_r = hemisphere_to_poincare(hs_r)\n",
    "            beta_ni = beta(i / 2, 1 / 2)\n",
    "            # logmap0: map from ball to tangent space at 0 (Euclidean space)\n",
    "            v_r = self.pball.logmap0(pball_r) * beta_n / beta_ni\n",
    "            mapped_rows.append(v_r)\n",
    "\n",
    "        # expmap0: map back to ball\n",
    "        flat_vec = th.cat(mapped_rows, dim=-1).contiguous().view(size[0], -1)\n",
    "        x = self.pball.expmap0(flat_vec)\n",
    "        return x\n",
    "\n",
    "    def undirectional_RMLR(self, C, weight_g, weight_v, gamma):\n",
    "        \"\"\"\n",
    "        修正后的前向传播\n",
    "        \"\"\"\n",
    "        # 1. 将相关矩阵映射到庞加莱球上的向量 x\n",
    "        # 形状: [Batch, Dim_Feature]\n",
    "        C_phi = self.correlation_to_poincare_concate(C)\n",
    "        \n",
    "        # 2. 修正 weight_v 的归一化\n",
    "        # weight_v 应该是参数，形状通常是 [Dim_Feature] 或者 [Dim_Feature, 1]\n",
    "        # 错误写法: weight_v.norm(dim=0) -> 如果 weight_v 是 [Dim]，dim=0 归一化整个向量得到标量，这本身没错\n",
    "        # 但如果 weight_v 是 [Batch, Dim] (这通常不对，权重一般不带 Batch)，或者 [Dim_Out, Dim_In]\n",
    "        \n",
    "        # 我们假设 weight_v 是一个方向向量，形状为 [Dim_Feature]\n",
    "        # 正确做法：对特征维度归一化\n",
    "        \n",
    "        # 为了兼容 matmul，通常希望 z_unit 是 [Dim_Feature]\n",
    "        weight_v_unit = weight_v / weight_v.norm(p=2, dim=-1, keepdim=True).clamp_min(1e-15)\n",
    "        \n",
    "        # 调用 MLR\n",
    "        # 注意：unidirectional_poincare_mlr 内部实现需要根据输入调整\n",
    "        # 这里我们稍微调整下传入参数以匹配我们上面定义的简化版 mlr\n",
    "        return unidirectional_poincare_mlr(C_phi, weight_g, weight_v_unit, gamma, c=self.c)\n",
    "\n",
    "# --- 3. 验证脚本 ---\n",
    "\n",
    "def test_normalization_logic():\n",
    "    print(\"=== 测试 1: 验证归一化逻辑 ===\")\n",
    "    \n",
    "    # 假设特征维度是 5\n",
    "    dim = 5\n",
    "    # 模拟一个权重向量\n",
    "    weight_v = th.randn(dim) \n",
    "    print(f\"原始 weight_v 形状: {weight_v.shape}\")\n",
    "    \n",
    "    # 错误方式 (dim=0): 对 1D 向量来说 dim=0 就是求向量的模，对于 1D 向量来说 dim=0 和 dim=-1 是一样的\n",
    "    # 但是！如果 weight_v 是为了多输出定义的 [Out_Dim, In_Dim]，dim=0 就是错误的\n",
    "    \n",
    "    # 让我们假设更复杂的情况：多类分类，权重通常是 [Num_Classes, Feature_Dim]\n",
    "    # 或者对于单向 MLR，weight_v 只是一个方向向量 [Feature_Dim]\n",
    "    \n",
    "    # 场景 A: weight_v 是 [Feature_Dim] (1D)\n",
    "    norm_0 = weight_v.norm(dim=0)\n",
    "    norm_last = weight_v.norm(dim=-1)\n",
    "    print(f\"1D向量下: dim=0={norm_0:.4f}, dim=-1={norm_last:.4f} (应该相等)\")\n",
    "    \n",
    "    # 场景 B: weight_v 误被定义为 [Batch, Dim] 或者 [Out, Dim]\n",
    "    # 假设这里我们只想定义一个方向，所以它是 1D 的。\n",
    "    # 修正的核心在于：keepdim=True\n",
    "    \n",
    "    weight_v_unit_fixed = weight_v / weight_v.norm(dim=-1, keepdim=True).clamp_min(1e-15)\n",
    "    print(f\"修正后单位向量模长: {weight_v_unit_fixed.norm().item():.4f} (应为 1.0)\")\n",
    "    print(f\"修正后形状: {weight_v_unit_fixed.shape}\")\n",
    "\n",
    "def test_forward_backward():\n",
    "    print(\"\\n=== 测试 2: 完整的前向和反向传播 ===\")\n",
    "    \n",
    "    n = 4 # 相关矩阵大小 4x4\n",
    "    batch_size = 2\n",
    "    \n",
    "    # 计算映射后的特征维度: n*(n-1)/2 = 4*3/2 = 6\n",
    "    feature_dim = int(n * (n - 1) / 2)\n",
    "    \n",
    "    model = CorPolyHyperbolicCholeskyMetric(n=n)\n",
    "    \n",
    "    # 模拟输入：正定相关矩阵 (通过随机矩阵生成)\n",
    "    A = th.randn(batch_size, n, n)\n",
    "    # 构造相关矩阵: A*A^T 然后归一化对角线\n",
    "    cov = th.bmm(A, A.transpose(1, 2))\n",
    "    d = th.sqrt(th.diagonal(cov, dim1=-2, dim2=-1))\n",
    "    outer_d = th.bmm(d.unsqueeze(2), d.unsqueeze(1))\n",
    "    C = cov / outer_d\n",
    "    C.requires_grad = True # 我们要测试梯度能否传回 C\n",
    "    \n",
    "    # 定义 MLR 的参数\n",
    "    # weight_g (标量或与 batch 对齐，通常是 margin 相关的模长增益)\n",
    "    weight_g = nn.Parameter(th.tensor(5.0))\n",
    "    \n",
    "    # weight_v (方向向量，维度应等于 feature_dim)\n",
    "    weight_v = nn.Parameter(th.randn(feature_dim))\n",
    "    \n",
    "    # gamma (margin)\n",
    "    gamma = nn.Parameter(th.tensor(0.5))\n",
    "    \n",
    "    print(f\"输入 C 形状: {C.shape}\")\n",
    "    print(f\"参数 weight_v 形状: {weight_v.shape}\")\n",
    "    \n",
    "    # --- 前向传播 ---\n",
    "    try:\n",
    "        output = model.undirectional_RMLR(C, weight_g, weight_v, gamma)\n",
    "        print(f\"前向传播成功。输出形状: {output.shape}\")\n",
    "        # 输出应该是 [Batch, 1] 或 [Batch, Batch] 取决于具体 MLR 实现，这里预期是 [Batch, 1] 表示 logit\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"前向传播失败: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return\n",
    "\n",
    "    # --- 反向传播 ---\n",
    "    try:\n",
    "        loss = output.mean()\n",
    "        loss.backward()\n",
    "        print(\"反向传播成功。\")\n",
    "        \n",
    "        # 检查梯度\n",
    "        if C.grad is not None:\n",
    "            print(f\"输入 C 的梯度范数: {C.grad.norm().item():.4f}\")\n",
    "        else:\n",
    "            print(\"错误: C 没有梯度\")\n",
    "            \n",
    "        if weight_v.grad is not None:\n",
    "            print(f\"参数 weight_v 的梯度范数: {weight_v.grad.norm().item():.4f}\")\n",
    "        else:\n",
    "            print(\"错误: weight_v 没有梯度\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"反向传播失败: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_normalization_logic()\n",
    "    test_forward_backward()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1121c2-a4e2-4d10-a2e5-b65b8018dfe9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
